---
layout: post
title: AWS Glue Overview
featured-img: shane-rounce-205187
image: shane-rounce-201587
categories: [Glue, AWS]
mathjax: true
summary: All we need to know about AWS Glue
---

# Table of Contents

This Page gives us an overview about all necessary topics about AWS Glue. It is divided into following parts:

1. [AWS Glue](#gluedefinition)
2. [Use Cases](#gluecase)
3. [Architecture](#gluearchitecture)
4. [Terminology](#glueterminology)
5. [Dockerization of our Nginx web server](#nginx)
6. [Assembling our Docker Containers using Docker-Compose](#compose)
7. [Testing our ML API using pytest](#testing)

<a name="gluedefinition"></a>
# 1. AWS Glue

- AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it simple and cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores and data streams. 
- AWS Glue consists of a central metadata repository known as the AWS Glue Data Catalog, an ETL engine that automatically generates Python or Scala code, and a flexible scheduler that handles dependency resolution, job monitoring, and retries.
- AWS Glue is serverless, so there’s no infrastructure to set up or manage.
- AWS Glue is designed to work with semi-structured data. 
- It introduces a component called a dynamic frame, which we can use in our ETL scripts. A dynamic frame is similar to an Apache Spark dataframe, which is a data abstraction used to organize data into rows and columns, except that each record is self-describing so no schema is required initially. With dynamic frames, we get schema flexibility and a set of advanced transformations specifically designed for dynamic frames. We can convert between dynamic frames and Spark dataframes, so that we can take advantage of both AWS Glue and Spark transformations to do the kinds of analysis that we want.
- We can use the AWS Glue console to discover data, transform it, and make it available for search and querying.
- We can also use the AWS Glue API operations to interface with AWS Glue services.
- We can use a familiar development environment to edit, debug, and test our Python or Scala Apache Spark ETL code.

<a name="gluecase"></a>
# 2. Use Cases

- We can use AWS Glue to organize, cleanse, validate, and format data for storage in a data warehouse or data lake.
- We can use AWS Glue when we run serverless queries against our Amazon S3 data lake. 
- We can create event-driven ETL pipelines with AWS Glue.
- We can use AWS Glue to understand our data assets.


<a name="gluearchitecture"></a>
# 3. Architecture

The following diagram shows the architecture of an AWS Glue environemnt.

![]({{ site.url }}/assets/img/posts/awsgluearchitecture.png)

We typically perform the following actions:
- For data store sources, we define a crawler to populate our AWS Glue Data Catalog with metadata table definitions. We point our crawler at a data store, and the crawler creates table definitions in the Data Catalog. For streaming sources, we manually define Data Catalog tables and specify data stream properties. In addition to table definitions, the AWS Glue Data Catalog contains other metadata that is required to define ETL jobs. We use this metadata when we define a job to transform our data.
- AWS Glue can generate a script to transform our data. Or, we can provide the script in the AWS Glue console or API.
- We can run our job on demand, or we can set it up to start when a specified trigger occurs. The trigger can be a time-based schedule or an event. When our job runs, a script extracts data from our data source, transforms the data, and loads it to our data target. The script runs in an Apache Spark environment in AWS Glue.

**IMPORTANT:** Tables and databases in AWS Glue are objects in the AWS Glue Data Catalog. They contain metadata; They do NOT contain data from a data store. Text-based data, such as CSVs, must be encoded in `UTF-8` for AWS Glue to process it successfully.

<a name="glueterminology"></a>
# 3. Terminology







# AWS Glue
- Glue is a fully managed serverless ETL service that automates the time-consuming steps of data preparation for analytics.
- Glue combines the speed and power of Apache Spark with the lightweight data organization of Hive metastores to GLUE together disparate data sources from across AWS
- Glue components help automate much of the undifferentiated heavy lifting involved with discovering, categorizing, cleaning, enriching, and moving data, so more time can be spent on analyzing the data.
- Glue automatically discovers and profiles the data via the Glue Data Catalog, recommends and generates ETL code to transform the source data into target schemas, and runs the ETL jobs on a fully managed, scale-out Apache Spark environment to load the data into its destination.
- Glue also helps setup, orchestrate, and monitor complex data flows.
- Glue consists of a 
  - Data Catalog, which is a central metadata repository, 
  - ETL engine that can automatically generate Scala or Python code,
  - Flexible scheduler that handles dependency resolution, job monitoring, and retries.
- Glue makes it simple and cost-effective to catalog, clean, enrich, and move data reliably between various data stores and streams.
- Glue is serverless and supports pay-as-you-go model. There is no infrastructure to provision or manage. 
- Glue supports data stored in
  - RDS (Aurora, MySQL, Oracle, PostgreSQL, SQL Server)
  - Redshift
  - DynamoDB
  - S3
  - JDBC databases in the Virtual Private Cloud (VPC) running on EC2
- Glue also supports custom Scala or Python code and import custom libraries and Jar files into the AWS Glue ETL jobs to access data sources not natively supported by AWS Glue.
- Glue provides development endpoints to edit, debug, and test the code it generates.
- Glue provides a unified view of the data via the Glue Data Catalog that is available for ETL, querying and reporting using services like Athena, EMR, and Redshift Spectrum.
- Glue can automatically discover both structured and semi-structured data stored in the data lake on S3, data warehouse in Redshift, and various databases running on AWS.
- Glue strives to address both data setup and processing in one place with minimal infrastructure setup. 
- - The Glue data catalog can make both file-based and traditional data sources available to Glue jobs, including schema detection through crawlers. 
- Glue’s data catalog can share a Hive metastore with AWS Athena, a convenient feature for existing Athena users like us.

![]({{ site.url }}/assets/img/posts/aws_glue_architecture.png)

**Usage patterns**
- Crawl your data and generate code to execute, including data transformation and loading
- Integrate with services like Athena, EMR, and Redshift
- Generates customizable, reusable, and portable ETL code using Python and Spark
- Glue's default timeout is two days and a good fit for jobs that were too long or too unpredictable - unlike Lambda's max of 15 minutes.
- Glue ETL supports serverless streaming ETL
  - Consumes from Kinesis or Managed Streaming for Kafka (MSK)
  - Clean & Transform in flight
  - Store results into S3 or other data stores 

![]({{ site.url }}/assets/img/posts/glueusagepattern.png)

**Cost**
- Hourly rate, billed by the minute, for crawler and ETL jobs
- Glue Data Catalog: pay a monthly fee for storing and accessing the metadata
  - First million objects stored and accesess are free for the Glue Data Catalog
- Development endpoints for developing ETL code charged by the minute

**Performance**
- Scale-out Apache Spark environment to load data to target data store
- Specify the number of Data Processing Units (DPUs) to allocate to your ETL job. 

**Durability and availability**
- Glue leverages the durability of the data stores to which you connect
- Provides job status and pushes notifications to CloudWatch events
- Use SNS notifications from CloudWatch events to notify of job failures or success

**Scalability and elasticity**
- Runs on top of the Apache Spark for transformation job scale-out execution

**Interfaces**
- Crawlers scan many data store types
- Bulk import Hive metastore into Glue Data Catalog

**Anti-patterns**
- Streaming data, unless Spark Streaming
- Heterogeneous ETL job types, i.e. if you want to use other engines (Hive, Pig, etc.) Data Pipeline, then EMR would be a better fit
- NoSQL databases: not supported as data source

**Security**
- IAM policies for the Glue service
- Configure Glue to only access JDBC through SSL
- Data Catalog: Encrypted by KMS
- Connection passwords: Encrypted by KMS
- Server-side Encryption (SSE) for data at rest
- SSL for data (in transit/motion)
- Data written by AWS Glue - Security Configurations:
  - S3 encryption mode: SSE-S3 or SSE-KMS
  - CloudWatch encryption mode
  - Job bookmark encryption mode 

**Monitoring**
- Fire off Lambda function or SNS for notification when ETL succeeds or fails
- Glue produces metrics for crawlers and jobs for monitoring
- Statistics are about the health of your environment and are written to the Glue Data Catalog
- Use automated monitoring tools to watch Glue and report problems
  - CloudWatch events
  - CloudWatch logs
  - CloudTrail logs


# AWS Glue Data Catalog

![]({{ site.url }}/assets/img/posts/glue_architecture.png)

- Glue Data Catalog is a central repository and persistent metadata store to store structural and operational metadata for all the data assets
- Glue Data Catalog provides a uniform repository where disparate systems can store and find metadata to keep track of data in data silos, and use that metadata to query and transform the data
- Table definitions once added to the Glue Data Catalog, are available for ETL and also readily available for querying in Athena, EMR, and Redshift Spectrum to provide a common view of the data between these services.
- Glue Data Catalog can serve as a Hive "metastore" and can also import a Hive metastore into Glue. Reminder: Hive lets you run SQL-like queries from EMR



# AWS Glue Crawler

- Glue Crawler connects to a data store, processes through a prioritized list of classifiers to extract the schema of the data and other statistics, and then populates the Glue Data Catalog with this metadata
- Glue Crawler scans various data stores to automatically infer schemas and partition structure to populate the Glue Data Catalog with corresponding table definitions and statistics.
- Glue Crawler can be scheduled to run periodically so that the metadata is always up-to-date and in-sync with the underlying data
- Glue Crawler automatically add new tables, new partitions to existing table, and new versions of table definitions
- Glue Crawler will extract paritions based on how your S3 data is organized.

## Dynamic Frames

- AWS Glue is designed to work with semi-structured data and introduces a component called a dynamic frame, which you can use in the ETL script
- Dynamic frame is a distributed table that supports nested data such as structures and arrays
- Each record is self-describing, designed for schema flexibility with semi-structured data. Each record contains both data and the schema that describes that data.
- A Dynamic Frame is similar to an Apache Spark dataframe, which is a data abstraction used to organize data into rows and columns, except that each record is self-describing so no schema is required initially.
- Dynamic frames provide schema flexibility and a set of advanced transformations specifically designed for dynamic frames.
- Conversion can be done between Dynamic frames and Spark dataframes, to take advantage of both AWS Glue and Spark transformations to do the kinds of analysis needed.

# Glue ETL on Apache Spark

- Use Glue ETL when you do not need or want to pay for an EMR cluster
- Fully managed, cost effective, pay only for the resources consumed
- Jobs runs on a serverless Spark platform
- Glue ETL jobs use the concept of concurrent data processing units (DPUs) to describe the compute capacity of a job run. A single DPU provides four virtual central processing units (vCPUs) and 16 GB of memory.

## Glue ETL Jobs - Structure
A Glue job defines the business logic that performs the ETL work in AWS Glue

- Glue runs your script to extract data from your sources, transform it, clean it, enrich it and load it into your targets
- Glue triggers can start jobs based on a schedule or event, or on demand.
- Monitor your job runs to get runtime metrics: completion status, duration, etc.
- Glue ETL generates automatically code in Python or Scala, which you can modify
- Glue ETL provides your own Spark or PySpark scripts

## Glue ETL Jobs - Types
Glue output file formats JSON, CSV, ORC (Optimized Row Columnar), Apache Parquet, and Apache Avro
Three types of Glue jobs:
- Spark ETL job: executed in managed Apache Spark environment, processes data in batches
- Streaming ETL job: uses the Apache Spark Structured Streaming framework
- Python shell job: schedule and run tasks that do not require an Apache Spark environment

## Glue ETL Jobs - Transformations
Glue has built-in transforms for processing data
- Call from within your ETL script
- In a DynamicFrame (an extension of an Apache Spark SQL DataFrame), your data passes from transfrom to transform
- Built-in transform types (subset)
  - ApplyMapping: maps source DynamicFrame columns and data types to target DynamicFrame columns and data types
  - Filter: selects records from a DynamicFrame and returns a filtered DynamicFrame
  - Map: applies a function to the records of a DynamicFrame and returns a transformed DynamicFrame
  - Relationalize: converts a DynamicFrame to a relational (rows and columns) form
- Machine Learning Transformations
  - FindMatches ML: identify duplicate or matching records in your dataset, even when the records do not have a common unique identifier and no fields match exactly
- Format conversions: CSV, JSON, Avro, Parquet, ORC, XML
- Apache Spark transformations, e.g. K-Means

## Glue ETL jobs - Triggers
A trigger can start specificed jobs and crawlers
- On demand, based on a schedule, or based on combination of events
- Add a trigger via the Glue console, the CLI or the Glue API
- Activate or deactivate a trigger via the Glue console, the CLI, or the Glue API

Profile your Glue jobs using metrics and visualize on the Glue and CloudWatch consoles to identify and fix issues

## AWS Glue Streaming ETL

- AWS Glue enables performing ETL operations on streaming data using continuously-running jobs.
- AWS Glue streaming ETL is built on the Apache Spark Structured Streaming engine, and can ingest streams from Kinesis Data Streams and Apache Kafka using Amazon Managed Streaming for Apache Kafka.
- Streaming ETL can clean and transform streaming data and load it into S3 or JDBC data stores.
- Use Streaming ETL in AWS Glue to process event data like IoT streams, clickstreams, and network logs.

## Glue Job Bookmarks
- Persists state from the job run
- Prevents reprocessing of old data
- Allows you to proces new data only when re-running on schedule
- Works with S3 sources in a variety of formats
- Works with JDBC (if PK's are in sequential order)
  - IMPORTANT: Only handles new ros, NOT updated rows 

# AWS Glue Studio
- Visual interface for ETL workflows
- Visual job editor
  - Create DAG's for complex workflows
  - Data Sources include S3, Kinesis, Kafka, JDBC
  - Allows Transform, sample and join data
  - Target to S3 or Glue Data Catalog
  - Support partitioning
- Visual job dashboard

# AWS Glue DataBrew
- A visual data preparation tool to clean and normalize data
  - UI for pre-processing large data sets
  - Input from S3, data warehouse, or database
  - Output to S3
- Over 250 read-made transformations avaiable
- You create steps of transformations that can be saved as jobs within a larger project
- Security:
  - KMS
  - SSL in transit
  - IAM can restrict who can do what
  - CloudWatch & CloudTrail


# Sources
- [https://medium.com/capital-one-tech/aws-glue-an-etl-solution-with-huge-potential-91a04a2a0712](https://medium.com/capital-one-tech/aws-glue-an-etl-solution-with-huge-potential-91a04a2a0712)
- [https://medium.com/@Synerzip/a-practical-guide-to-aws-glue-7bc3f86c2820](https://medium.com/@Synerzip/a-practical-guide-to-aws-glue-7bc3f86c2820)
- [https://towardsdatascience.com/aws-glue-101-all-you-need-to-know-with-a-real-world-example-f34af17b782f](https://towardsdatascience.com/aws-glue-101-all-you-need-to-know-with-a-real-world-example-f34af17b782f)
